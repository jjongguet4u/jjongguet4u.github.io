---
layout: post
title:  "4. 하이퍼파라미터 최적화 W&B Sweeps"
subtitle:   "MLops4"
categories: in
tags: mlopsstudy
comments: true
---
# gridsearch

gridsearch란 일종의 하이퍼파라미터 테이블이라고 쉽게 표현한다


<img src="/assets/img/202109/0907/8.jpg">  


예를들어 딥러닝의 첫번째 레이어에서. 모델성능이 가장 좋게 나타나는 레이어 갯수를 알고싶다면

layers를 32일때, 64일때, 128일때, 256일때를 모두 변수화 시켜서 사용해야하는것이다.

그렇게 되면 소스코드는 4개가 되고, 그만큼 내용이 복잡해진다.

# Sweeps

sweeps는 grid search와 맥락은 비슷한데, 사용법이 조금 다르다

참고페이지 : [https://gitbook-docs.wandb.ai/guides/sweeps/configuration](https://gitbook-docs.wandb.ai/guides/sweeps/configuration)

```python
%pip install -q wandb
!wandb login
```

### 기존코드

[https://github.com/wandb/examples/blob/master/examples/wandb-sweeps/sweeps-python/notebook.ipynb](https://github.com/wandb/examples/blob/master/examples/wandb-sweeps/sweeps-python/notebook.ipynb)

train하는 내용을 먼저 정의한다

```python
# %load train_lib.py

def train():
    import numpy as np
    import tensorflow as tf
    import wandb
    config_defaults = {
        'layers': 128
    }
    wandb.init(config=config_defaults, magic=True)

    fashion_mnist = tf.keras.datasets.fashion_mnist
    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()
    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
                   'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

    train_images.shape
    train_images = train_images / 255.0
    test_images = test_images / 255.0

    model = tf.keras.Sequential([
        tf.keras.layers.Flatten(input_shape=(28, 28)),
        tf.keras.layers.Dense(wandb.config.layers, activation=tf.nn.relu),
        tf.keras.layers.Dense(10, activation=tf.nn.softmax)
    ])

    model.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
    
    model.fit(train_images, train_labels, epochs=5,
                  validation_data=(test_images, test_labels))
```

layers의 values종류를 설정한다. 딕셔너리형태와 그냥 리스트형태를 주의하도록 하자

해당 내용의 search space는 layers에 대한 내용이다. 

```python
sweep_config = {
    'method': 'grid',
    'parameters': {
        'layers': {
            'values': [32, 64, 96, 128, 256]
        }
    }
}
```

wandb를 가져오고, wandb.sweep()으로 실험환경을 완성한다

```python
import wandb
sweep_id = wandb.sweep(sweep_config)
```

해당경우에는 wandb의 agent를 하나 띄워서 진행한다

```python
wandb.agent(sweep_id, function=train)
```

### 변경코드

```python
%pip install -q wandb
!wandb login
```

```python
# %load train_lib.py

def train():
    import numpy as np
    import tensorflow as tf
    import wandb
    config_defaults = {
        'layer1_size': 128,
        'dropout_rate' : 0.2,
        'layer1_activation': 'relu',
        'optimizer': 'adam',
        'learning_rate' : 0.01
    }
    wandb.init(project='wandb-sweep-practice', config=config_defaults, magic=True)
    config = wandb.config

    fashion_mnist = tf.keras.datasets.fashion_mnist
    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()
    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
                   'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

    train_images.shape
    train_images = train_images / 255.0
    test_images = test_images / 255.0

    model = tf.keras.Sequential([
        tf.keras.layers.Flatten(input_shape=(28, 28)),
        tf.keras.layers.Dense(wandb.layer1_size, activation=config.layer1_activation),
        tf.keras.layers.Dropout(config.dropout_rate),
        tf.keras.layers.Dense(10, activation=tf.nn.softmax)
    ])
    opt = tf.keras.optimizer.Adam(learning_rate  = config.learning_rate)\

    if config.optimizer == 'rmsprop' :
        opt = tf.keras.optimizers.RMSProp(learning_rate = config.learning_rate)
    else : 
        opt = tf.keras.optimizers.Adam(learning_Rate = config.learning_rate)
    model.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
    
    model.fit(train_images, train_labels, epochs=5,
                  validation_data=(test_images, test_labels))
```

1. `wandb.init` 에서 프로젝트이름, 기본config설정을 먼저 진행하고
2. `config = wandb.config` 로 기본인자를 넣어준다
3. search space를 먼저 정의

    ```python
    sweep_config = {
        'method': 'grid',
        'parameters': {
            'layers': {
                'values': [32, 64, 96, 128, 256]
            },
            'layer1_activation' : {
                'values' : ['relu','sigmoid']
            },
            'dropout_rate' : {
                'values' : [0.1,0.2,0.3,0.4,0.5]
            },
            'optimizer': {
                'values' : ['adam', 'rmsprop']
            },
            'learning_rate': {
                'values' : [0.1, 0.01, 0.001]
            }
        }
    }
    ```

1. 파라미터에 맞게 모델변경

    ```python
    #이전에서    
    model = tf.keras.Sequential([
            tf.keras.layers.Flatten(input_shape=(28, 28)),
            tf.keras.layers.Dense(wandb.config.layers, activation=tf.nn.relu),
            tf.keras.layers.Dense(10, activation=tf.nn.softmax)
        ])
    ```

    ```python
    #이후로 변경해주기
    model = tf.keras.Sequential([
            tf.keras.layers.Flatten(input_shape=(28, 28)),
            tf.keras.layers.Dense(wandb.layer1_size, activation=config.layer1_activation),
            tf.keras.layers.Dropout(config.dropout_rate),
            tf.keras.layers.Dense(10, activation=tf.nn.softmax)
        ])
    opt = tf.keras.optimizer.Adam(learning_rate  = config.learning_rate)

    #optimizer변수가 다를때를 정의
    if config.optimizer == 'rmsprop' :
        opt = tf.keras.optimizers.RMSProp(learning_rate = config.learning_rate)
    else : 
        opt = tf.keras.optimizers.Adam(learning_Rate = config.learning_rate)
    model.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])

    ```

1. wandb연결

    ```python
    import wandb
    sweep_id = wandb.sweep( sweep_config, project='wandb-sweep-practice')
    ```

2. agent만들어서 확인하기

    ```python
    wandb.agent(sweep_id, function=train)
    ```

    
    <img src="/assets/img/202109/0907/9.jpg">  
